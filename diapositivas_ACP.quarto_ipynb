{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Análisis de Componentes Principales\"\n",
        "subtitle: \"Explorando la reducción de dimensionalidad\"\n",
        "author: \"Tu Nombre\"\n",
        "date: \"26 de noviembre de 2025\"\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: default\n",
        "    transition: \"slide\"\n",
        "    slide-number: true\n",
        "    center: false\n",
        "    progress: true\n",
        "    hash: true\n",
        "    width: 1200\n",
        "    height: 800\n",
        "    font-family: \"Inter, sans-serif\"\n",
        "    highlight-style: \"github-dark\"\n",
        "    self-contained: true\n",
        "---\n",
        "\n",
        "```{css, echo=FALSE}\n",
        "/* Estilos adicionales para personalización */\n",
        ".reveal .slide-logo {\n",
        "  opacity: 0.1 !important;\n",
        "}\n",
        ".reveal h1 {\n",
        "  font-weight: 800;\n",
        "  color: #2c3e50;\n",
        "}\n",
        ".reveal h2 {\n",
        "  color: #3498db;\n",
        "  border-bottom: 2px solid #eee;\n",
        "  padding-bottom: 0.3em;\n",
        "  margin-top: 1em;\n",
        "}\n",
        ".reveal p {\n",
        "  line-height: 1.6;\n",
        "  color: #34495e;\n",
        "}\n",
        ".reveal li {\n",
        "  margin-bottom: 0.5em;\n",
        "}\n",
        ".reveal section.has-dark-background,\n",
        ".reveal section.has-dark-background h1,\n",
        ".reveal section.has-dark-background h2,\n",
        ".reveal section.has-dark-background p {\n",
        "  color: #f8f9fa;\n",
        "}\n",
        ".reveal .index-item {\n",
        "  padding: 0.8em;\n",
        "  margin: 0.4em 0;\n",
        "  background: rgba(52, 152, 219, 0.08);\n",
        "  border-radius: 8px;\n",
        "  transition: all 0.3s ease;\n",
        "  cursor: pointer;\n",
        "}\n",
        ".reveal .index-item:hover {\n",
        "  background: rgba(52, 152, 219, 0.2);\n",
        "  transform: translateX(5px);\n",
        "}\n",
        ".reveal .icon {\n",
        "  margin-right: 8px;\n",
        "  color: #3498db;\n",
        "}\n",
        ".reveal .highlight-box {\n",
        "  background: linear-gradient(135deg, #f5f7fa 0%, #e4edf9 100%);\n",
        "  padding: 1.2em;\n",
        "  border-radius: 12px;\n",
        "  border-left: 4px solid #3498db;\n",
        "  margin: 1em 0;\n",
        "}\n",
        ".center-img {\n",
        "  display: block;\n",
        "  margin: 0 auto;\n",
        "  max-height: 400px;\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "# 4.1.1: Las componentes principales como direcciones en las que la matriz de datos tiene la máxima varianza\n",
        "\n",
        "---\n",
        "\n",
        "## Contexto inicial y preparación de datos\n",
        "\n",
        "Partimos de una matriz de datos original:\n",
        "\n",
        "$$\n",
        "X_{n \\times p} = \\{x_{ij}\\}\n",
        "$$\n",
        "donde:\n",
        "- $n$: número de objetos (individuos, ciudades, etc.)\n",
        "- $p$: número de variables\n",
        "- $x_{ij}$: valor de la variable $j$ en el objeto $i$\n",
        "\n",
        "### Estadísticos básicos por variable:\n",
        "- Media: $\\bar{x}_j = \\frac{1}{n}\\sum_{i=1}^n x_{ij}$\n",
        "- Varianza: $s_j^2 = \\frac{1}{n}\\sum_{i=1}^n (x_{ij} - \\bar{x}_j)^2$\n",
        "\n",
        "### **Matriz de datos centrados y estandarizados:**\n",
        "$$\n",
        "Y_{n \\times p} = \\{y_{ij}\\} = \\left\\{\\frac{x_{ij} - \\bar{x}_j}{s_j}\\right\\}\n",
        "$$\n",
        "\n",
        "**Propiedades de Y:**\n",
        "- Media cero: $\\bar{Y}_j = \\frac{1}{n}\\sum_{i=1}^n y_{ij} = 0$\n",
        "- Varianza unitaria: $var(Y_j) = \\frac{1}{n}\\sum_{i=1}^n y_{ij}^2 = 1$\n",
        "\n",
        "---\n",
        "\n",
        "##  Representación de la matriz Y\n",
        "\n",
        "Podemos ver $Y$ de dos formas:\n",
        "\n",
        "1. **Como vectores fila:** $y_i' = (y_{i1}, y_{i2}, \\ldots, y_{ip})$ para $i = 1,\\ldots,n$  \n",
        "   → Análisis de similitudes entre objetos\n",
        "\n",
        "2. **Como vectores columna:** $Y_j = (y_{1j}, y_{2j}, \\ldots, y_{nj})'$ para $j = 1,\\ldots,p$  \n",
        "   → Análisis de asociaciones entre variables\n",
        "\n",
        "---\n",
        "\n",
        "## Primera componente principal: dirección de máxima varianza\n",
        "\n",
        "### **Objetivo:**\n",
        "Encontrar un vector de ponderaciones $u_1' = (u_{11}, \\ldots, u_{p1})$ normalizado ($u_1'u_1 = 1$) que maximice la varianza de la combinación lineal:\n",
        "$$\n",
        "z_{i1} = u_1'y_i = \\sum_{j=1}^p u_{j1}y_{ij}\n",
        "$$\n",
        "\n",
        "###Formulación del problema de optimización:\n",
        "\n",
        "La varianza de $z_1$ es:\n",
        "$$\n",
        "var(z_1) = \\frac{1}{n}\\sum_{i=1}^n z_{i1}^2 = \\frac{1}{n}\\sum_{i=1}^n \\left(\\sum_{j=1}^p u_{j1}y_{ij}\\right)^2\n",
        "$$\n",
        "\n",
        "**Problema de optimización:**\n",
        "$$\n",
        "\\max_{u_{11},\\ldots,u_{p1}} \\left\\{ \\frac{1}{n}\\sum_{i=1}^n \\left(\\sum_{j=1}^p u_{j1}y_{ij}\\right)^2 \\right\\}\n",
        "$$\n",
        "sujeto a: $\\sum_{j=1}^p u_{j1}^2 = 1$\n",
        "\n",
        "---\n",
        "\n",
        "## Resolución mediante multiplicadores de Lagrange\n",
        "\n",
        "### Función de Lagrange:\n",
        "$$\n",
        "\\mathcal{L}(u_1, \\lambda) = u_1'Ru_1 - \\lambda(u_1'u_1 - 1)\n",
        "$$\n",
        "donde $R = \\frac{1}{n}Y'Y$ es la **matriz de correlación** (cuando trabajamos con datos estandarizados).\n",
        "\n",
        "### Derivadas e igualación a cero:\n",
        "\n",
        "1. **Derivada respecto a $u_1$:**\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial u_1} = 2Ru_1 - 2\\lambda u_1 = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow Ru_1 = \\lambda u_1\n",
        "$$\n",
        "\n",
        "2. **Derivada respecto a $\\lambda$:**\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = u_1'u_1 - 1 = 0\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow u_1'u_1 = 1\n",
        "$$\n",
        "\n",
        "### Interpretación del resultado:\n",
        "\n",
        "La ecuación $Ru_1 = \\lambda u_1$ nos dice que:\n",
        "- $u_1$ es un **vector propio** de la matriz $R$\n",
        "- $\\lambda$ es el **valor propio** correspondiente\n",
        "\n",
        "Para **maximizar la varianza**, elegimos el **mayor valor propio** $\\lambda_1$ de $R$, y su vector propio correspondiente $u_1$.\n",
        "\n",
        "---\n",
        "\n",
        "## Segunda componente principal\n",
        "\n",
        "### **Objetivo:**\n",
        "Encontrar un segundo vector $u_2' = (u_{12}, \\ldots, u_{p2})$ que:\n",
        "- Sea ortogonal a $u_1$: $u_1'u_2 = 0$\n",
        "- Esté normalizado: $u_2'u_2 = 1$\n",
        "- Maximice la varianza de $z_2 = Yu_2$\n",
        "\n",
        "### **Problema de optimización:**\n",
        "$$\n",
        "\\max_{u_2} \\left\\{ \\frac{1}{n}\\sum_{i=1}^n \\left(\\sum_{j=1}^p u_{j2}y_{ij}\\right)^2 \\right\\}\n",
        "$$\n",
        "sujeto a:\n",
        "- $u_2'u_2 = 1$\n",
        "- $u_1'u_2 = 0$\n",
        "\n",
        "### **Función de Lagrange ampliada:**\n",
        "$$\n",
        "\\mathcal{L}(u_2, \\lambda_2, \\gamma) = u_2'Ru_2 - \\lambda_2(u_2'u_2 - 1) - \\gamma u_1'u_2\n",
        "$$\n",
        "\n",
        "### **Derivadas:**\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial u_2} = 2Ru_2 - 2\\lambda_2 u_2 - \\gamma u_1 = 0\n",
        "$$\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\lambda_2} = u_2'u_2 - 1 = 0\n",
        "$$\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial \\gamma} = u_1'u_2 = 0\n",
        "$$\n",
        "\n",
        "### **Demostración de que $\\gamma = 0$:**\n",
        "\n",
        "Multiplicamos la primera ecuación por $u_1'$ por la izquierda:\n",
        "$$\n",
        "2u_1'Ru_2 - 2\\lambda_2 u_1'u_2 - \\gamma u_1'u_1 = 0\n",
        "$$\n",
        "\n",
        "Sabemos que:\n",
        "- $u_1'u_2 = 0$ (restricción de ortogonalidad)\n",
        "- $u_1'u_1 = 1$ (normalización)\n",
        "- $u_1'Ru_2 = u_1'(\\lambda_1 u_1)'u_2 = \\lambda_1 u_1'u_2 = 0$\n",
        "\n",
        "Por tanto:\n",
        "$$\n",
        "0 - 0 - \\gamma(1) = 0 \\Rightarrow \\gamma = 0\n",
        "$$\n",
        "\n",
        "### **Solución:**\n",
        "Con $\\gamma = 0$, la ecuación se reduce a:\n",
        "$$\n",
        "Ru_2 = \\lambda_2 u_2\n",
        "$$\n",
        "\n",
        "Nuevamente, $u_2$ es un **vector propio** de $R$, y para maximizar la varianza elegimos el **segundo mayor valor propio** $\\lambda_2$.\n",
        "\n",
        "---\n",
        "\n",
        "## Componentes principales generales\n",
        "\n",
        "### **Para el α-ésimo componente:**\n",
        "$$\n",
        "z_{i\\alpha} = \\sum_{j=1}^p u_{j\\alpha}y_{ij} = y_i'u_\\alpha\n",
        "$$\n",
        "$$\n",
        "z_\\alpha = Yu_\\alpha\n",
        "$$\n",
        "donde $u_\\alpha$ es el α-ésimo vector propio de $R$ asociado al α-ésimo mayor valor propio $\\lambda_\\alpha$.\n",
        "\n",
        "### **Propiedades:**\n",
        "1. **Media cero:** $m(z_\\alpha) = 0$\n",
        "2. **Varianza:** $var(z_\\alpha) = \\lambda_\\alpha$\n",
        "3. **Ortogonalidad:** $z_\\alpha' z_\\beta = 0$ para $\\alpha \\neq \\beta$\n",
        "\n",
        "---\n",
        "\n",
        "## Interpretación geométrica\n",
        "\n",
        "Cada componente principal $z_\\alpha$ representa la **proyección** de los datos originales sobre la dirección definida por el vector propio $u_\\alpha$.\n",
        "\n",
        "La **varianza explicada** por cada componente es exactamente igual al valor propio correspondiente:\n",
        "$$\n",
        "var(z_\\alpha) = \\lambda_\\alpha\n",
        "$$\n",
        "\n",
        "El **porcentaje de varianza explicada** por la α-ésima componente es:\n",
        "$$\n",
        "\\tau_\\alpha = \\frac{\\lambda_\\alpha}{\\sum_{\\alpha=1}^p \\lambda_\\alpha}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## Resumen del procedimiento\n",
        "\n",
        "1. **Centrar y estandarizar** los datos: $Y = \\left\\{\\frac{x_{ij}-\\bar{x}_j}{s_j}\\right\\}$\n",
        "2. **Calcular matriz de correlación:** $R = \\frac{1}{n}Y'Y$\n",
        "3. **Descomposición espectral:** Encontrar valores y vectores propios de $R$\n",
        "4. **Ordenar** valores propios en forma descendente: $\\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_p$\n",
        "5. **Componentes principales:** $z_\\alpha = Yu_\\alpha$, donde $u_\\alpha$ es el α-ésimo vector propio\n",
        "6. **Seleccionar** las primeras $q$ componentes que acumulen suficiente varianza\n",
        "\n",
        "---\n",
        "\n",
        "Esta aproximación del ACP busca **direcciones de máxima varianza** en los datos, proporcionando una base ortogonal óptima para representar la información contenida en la matriz original con dimensionalidad reducida."
      ],
      "id": "cf39fa2f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}